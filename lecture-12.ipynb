{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "np.random.seed(42)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Week 12: Predictive Modeling Part 2\n",
    "Nov 21, 2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Housekeeping\n",
    "\n",
    "- Class is on Tuesday 11/26 next week (same time) because of Thanksgiving\n",
    "- HW #7 (required) is due next week\n",
    "    - Includes final project proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Last time\n",
    "\n",
    "- An introduction to supervised learning and regression with scikit learn\n",
    "- **Example:** modeling housing prices in Philadelphia\n",
    "- **Key concepts:**\n",
    "    - Linear regression\n",
    "    - Ridge regression with regularization \n",
    "    - Test/train split and $k$-fold cross validation\n",
    "    - Feature engineering\n",
    "        - Scaling input features\n",
    "        - Adding polynomial features\n",
    "        - One-hot encoding + categorical variables\n",
    "    - Decision trees and random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Today: Predictive modeling continued\n",
    "\n",
    "**Focus**: featuring engineering and adding spatial based features\n",
    "\n",
    "- **Part 1:** Revisiting housing prices modeling\n",
    "- **Part 2:** Predicting bikeshare demand in Philadelphia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 1: Adding spatial features to the housing price model\n",
    "\n",
    "Recall:\n",
    "\n",
    "- Modeling residential sale prices for sales in 2018 with data from the Office of Property Assessment\n",
    "- Model included: property characteristics and ZIP code categorical variables\n",
    "- Random forest model showed good improvement over standard linear regression (ordinary least squares)\n",
    "\n",
    "**Let's do some additional feature engineering to see if we can improve the model's accuracy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, let's setup all of the imports we'll need from scikit learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing/Setup\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's load the same data as last week\n",
    "\n",
    "Query the city's CARTO cloud database to pull the data for all residential sales in 2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import carto2gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# the CARTO API url\n",
    "carto_url = \"https://phl.carto.com/api/v2/sql\"\n",
    "\n",
    "# The table name\n",
    "table_name = \"opa_properties_public\"\n",
    "\n",
    "# Only pull 2018 sales for single family residential properties\n",
    "where = \"sale_date >= '2018-01-01' and sale_date < '2019-01-01' and category_code_description = 'Single Family'\"\n",
    "\n",
    "# Run the query\n",
    "salesRaw = carto2gpd.get(carto_url, table_name, where=where)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "salesRaw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "len(salesRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clean the raw data\n",
    "\n",
    "- Remove features with a large number of missing values\n",
    "- Format the ZIP code column\n",
    "- Trim to sales between \\\\$3,000 and \\\\$1 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The feature columns we want to use\n",
    "cols = [\n",
    "    \"sale_price\",\n",
    "    \"total_livable_area\",\n",
    "    \"total_area\",\n",
    "    \"garage_spaces\",\n",
    "    \"fireplaces\",\n",
    "    \"number_of_bathrooms\",\n",
    "    \"number_of_bedrooms\",\n",
    "    \"number_stories\",\n",
    "    \"exterior_condition\",\n",
    "    \"zip_code\",\n",
    "    \"geometry\"\n",
    "]\n",
    "\n",
    "# Trim to these columns and remove NaNs\n",
    "sales = salesRaw[cols].dropna()\n",
    "\n",
    "# Trim zip code to only the first five digits\n",
    "sales['zip_code'] = sales['zip_code'].astype(str).str.slice(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Trim very low and very high sales\n",
    "valid = (sales['sale_price'] > 3000) & (sales['sale_price'] < 1e6)\n",
    "sales = sales.loc[valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "len(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Remember: One-hot encoding in scikit learn\n",
    "\n",
    "- The [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) object is a preprocessor that will perform the vectorization step\n",
    "- The [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) object will help us apply different transformers to numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Numerical columns\n",
    "num_cols = [\n",
    "    \"total_livable_area\",\n",
    "    \"total_area\",\n",
    "    \"garage_spaces\",\n",
    "    \"fireplaces\",\n",
    "    \"number_of_bathrooms\",\n",
    "    \"number_of_bedrooms\",\n",
    "    \"number_stories\",\n",
    "]\n",
    "\n",
    "# Categorical columns\n",
    "cat_cols = [\"exterior_condition\", \"zip_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the column transformer with two transformers\n",
    "# Scale the numerical columns and one-hot \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the pipeline\n",
    "# NOTE: only use 20 estimators here so it will run in a reasonable time\n",
    "regr = make_pipeline(\n",
    "    preprocessor, RandomForestRegressor(n_estimators=20, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now, let's fit the model (same as last week)\n",
    "\n",
    "- Use a 70%/30% train/test split — 30% of data is reserved for final testing\n",
    "- Use the log of the sale price as the target values to regress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data 70/30\n",
    "train_set, test_set = train_test_split(sales, test_size=0.3, random_state=42)\n",
    "\n",
    "# the target labels\n",
    "y_train = np.log(train_set[\"sale_price\"])\n",
    "y_test = np.log(test_set[\"sale_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the training set\n",
    "regr.fit(train_set, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# What's the test score?\n",
    "regr.score(test_set, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's plot the top 30 importances\n",
    "\n",
    "To do so, remember, we'll need to get the names of the columns created during the one-hot encoding process..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The one-hot step\n",
    "ohe = preprocessor.named_transformers_['cat']\n",
    "\n",
    "# One column for each category type!\n",
    "ohe_cols = ohe.get_feature_names()\n",
    "\n",
    "# Full list of columns is numerical + one-hot\n",
    "features = num_cols + list(ohe_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "regressor = regr[\"randomforestregressor\"]\n",
    "\n",
    "# Create the dataframe with importances\n",
    "importance = pd.DataFrame(\n",
    "    {\"Feature\": features, \"Importance\": regressor.feature_importances_}\n",
    ")\n",
    "\n",
    "# Sort by importance and get the top 30\n",
    "# MAKE SURE TO SORT IN DESCENDING ORDER!!\n",
    "importance = importance.sort_values(\"Importance\", ascending=False).iloc[:30]\n",
    "\n",
    "# Plot\n",
    "importance.hvplot.barh(\n",
    "    x=\"Feature\", y=\"Importance\", height=500, flip_yaxis=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Improving the model even further\n",
    "\n",
    "- Adding in ZIP code information captures a lot of the neighborhood-based amenity/disamenity properties\n",
    "- Can we explicitly add new features that also try to capture some of those features?\n",
    "\n",
    "**Yes, let's add distance-based features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Spatial amenity/disamenity features\n",
    "\n",
    "**The strategy**\n",
    "\n",
    "- Get the data for a certain type of amenity, e.g., restaurants, bars, or disamenity, e.g., crimes\n",
    "    - Data sources: 311 requests, crime incidents, Open Street Map\n",
    "- Use scikit learn's nearest neighbor algorithm to calculate the distance from each sale to its nearest neighbor in the amenity/disamenity datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examples of new possible features...\n",
    "\n",
    "Distance from each sale to:\n",
    "\n",
    "- Universities\n",
    "- Parks\n",
    "- City Hall\n",
    "- Subway Stops\n",
    "- New Construction Permits\n",
    "- Aggravated Assaults\n",
    "- Graffiti 311 Calls\n",
    "- Abandoned Vehicle 311 Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example #1: 311 Graffiti Calls\n",
    "\n",
    "Source: https://www.opendataphilly.org/dataset/311-service-and-information-requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 1: Download the data from the CARTO database\n",
    "\n",
    "\n",
    "We'll only pull data from 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# the 311 table\n",
    "table_name = \"public_cases_fc\"\n",
    "\n",
    "# Peak at the first row of data\n",
    "carto2gpd.get(carto_url, table_name, limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Select only those for grafitti and in 2018\n",
    "where_2018 = \"requested_datetime >= '01-01-2018' and requested_datetime < '01-01-2019'\"\n",
    "where_grafitti = \"service_name = 'Graffiti Removal'\"\n",
    "where = f\"{where_2018} and {where_grafitti}\"\n",
    "\n",
    "# Pull the subset we want\n",
    "graffiti = carto2gpd.get(carto_url, table_name, where=where)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Remove rows with missing geometries\n",
    "graffiti = graffiti.loc[graffiti.geometry.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "len(graffiti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "graffiti.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 2: Get the x/y coordinates of both datasets\n",
    "\n",
    "We will need to:\n",
    "\n",
    "- We'll want distances in meters (rather than degrees), so we'll convert the CRS to EPSG=3857\n",
    "- Extract out the x/y coordinates of the geometry column of each dataset (sales and grafitti calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Do the CRS conversion\n",
    "sales_3857 = sales.to_crs(epsg=3857)\n",
    "graffiti_3857 = graffiti.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_xy_from_geometry(df):\n",
    "    \"\"\"\n",
    "    Return a numpy array with two columns, where the \n",
    "    first holds the `x` geometry coordinate and the second \n",
    "    column holds the `y` geometry coordinate\n",
    "    \"\"\"\n",
    "    x = df.geometry.x\n",
    "    y = df.geometry.y\n",
    "    \n",
    "    return np.column_stack((x, y)) # stack as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Extract x/y for sales\n",
    "salesXY = get_xy_from_geometry(sales_3857)\n",
    "\n",
    "# Extract x/y for grafitti calls\n",
    "graffitiXY = get_xy_from_geometry(graffiti_3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "salesXY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "graffitiXY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 3: Calculate the nearest neighbor distances\n",
    "\n",
    "For this, we will use the $k$ nearest neighbors algorithm from scikit learn.\n",
    "\n",
    "For each sale:\n",
    "- Find the $k$ nearest neighbors in the second dataset (graffiti calls, crimes, etc)\n",
    "- Calculate the average distance from the sale to those $k$ neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# STEP 1: Initialize the algorithm\n",
    "k = 5\n",
    "nbrs = NearestNeighbors(n_neighbors=k)\n",
    "\n",
    "# STEP 2: Fit the algorithm on the \"neighbors\" dataset\n",
    "nbrs.fit(graffitiXY)\n",
    "\n",
    "# STEP 3: Get distances for sale to \n",
    "grafDists, grafIndices = nbrs.kneighbors(salesXY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***Note:** I am using `k=5` here without any real justification. In practice, you would want to try a few different k values to try to identify the best value to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What did we just calculate?\n",
    "\n",
    "- `grafDists`: For each sale, the distances to the 5 nearest graffiti calls\n",
    "    - This should have 5 columns and the same length as the sales dataset\n",
    "- `grafIndices`: For each sale, the index of each of the neighbors in the original dataset\n",
    "    - This allows you to access the original 311 graffiti data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"length of sales = \", len(salesXY))\n",
    "print(\"shape of grafDists = \", grafDists.shape)\n",
    "print(\"shape of grafIndices = \", grafIndices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The distances from the first sale to the 5 nearest neighbors\n",
    "grafDists[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Can we reproduce these distances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The coordinates for the first sale\n",
    "x0, y0 = salesXY[0]\n",
    "x0, y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The indices for the 5 nearest graffiti calls\n",
    "grafIndices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# the graffiti neighbors\n",
    "sale0_neighbors = graffitiXY[grafIndices[0]]\n",
    "sale0_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Access the first and second column for x/y values\n",
    "neighbors_x = sale0_neighbors[:,0]\n",
    "neighbors_y = sale0_neighbors[:,1]\n",
    "\n",
    "# The x/y differences between neighbors and first sale coordinates\n",
    "dx = (neighbors_x - x0)\n",
    "dy = (neighbors_y - y0)\n",
    "\n",
    "# The Euclidean dist\n",
    "manual_dists = (dx**2 + dy**2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "manual_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "grafDists[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use the log of the average distance as the new feature\n",
    "\n",
    "We'll average over the column axis (`axis=1`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Average distance to neighbors\n",
    "avgGrafDist = grafDists.mean(axis=1)\n",
    "\n",
    "# Set zero distances to be small, but nonzero\n",
    "# IMPORTANT: THIS WILL AVOID INF DISTANCES WHEN DOING THE LOG\n",
    "avgGrafDist[avgGrafDist==0] = 1e-5\n",
    "\n",
    "# Calculate log of distances\n",
    "sales['logDistGraffiti'] = np.log10(avgGrafDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's plot a hex map of the new feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Load the City Limits to plot too\n",
    "import esri2gpd\n",
    "\n",
    "# From OpenDataPhilly's page\n",
    "url = \"https://services.arcgis.com/fLeGjb7u4uXqeF9q/arcgis/rest/services/City_Limits/FeatureServer/0\"\n",
    "city_limits = esri2gpd.get(url).to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10), facecolor=plt.get_cmap('viridis')(0))\n",
    "\n",
    "# Plot the log of the Graffiti distance\n",
    "x = salesXY[:,0]\n",
    "y = salesXY[:,1]\n",
    "ax.hexbin(x, y, C=sales['logDistGraffiti'].values, gridsize=60)\n",
    "\n",
    "# Plot the city limits\n",
    "city_limits.plot(ax=ax, facecolor='none', edgecolor='white', linewidth=4)\n",
    "\n",
    "ax.set_axis_off()\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example #2: Subway stops\n",
    "\n",
    "We'll use a new package `osm2gpd` to pull subway stops from Open Street Map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import osm2gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Similar syntax to the other packages to query CARTO and ESRI Map Servers (carto2gpd and esri2gpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "osm2gpd.get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What we need:\n",
    "\n",
    "1. Bounding box in lat/lng to search within — we can use the city limits\n",
    "1. The type of feature to search for.\n",
    "    - For a full list, see: http://wiki.openstreetmap.org/wiki/Map_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Bounding box from city limits\n",
    "# CONVERT TO EPSG=4326 FIRST!\n",
    "lng_min, lat_min, lng_max, lat_max = city_limits.to_crs(epsg=4326).total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Grab subway stations\n",
    "where=\"station=subway\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "subway = osm2gpd.get(lng_min, lat_min, lng_max, lat_max, where=where).to_crs(epsg=3857)\n",
    "subway.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Important: we need to trim to just Philadelphia\n",
    "\n",
    "- Since we only supplied a rectangular bounding box, it's possible some features will be outside Philadelphia's city limits.\n",
    "- We can do a spatial join with the city limits to find those featueres within the city bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "subway = gpd.sjoin(subway, city_limits, op=\"within\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What data did we get?\n",
    "\n",
    "The point locations of the Broad St. and Markford-Frankford subway stops!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "# Plot the subway locations\n",
    "subway.plot(ax=ax, markersize=5, color='crimson')\n",
    "\n",
    "# City limits, too\n",
    "city_limits.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=4)\n",
    "\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now, get the distances to the nearest subway stop\n",
    "\n",
    "We'll use $k=1$ to get the distance to the nearest stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# STEP 1: x/y coordinates of subway stops (in EPGS=3857)\n",
    "subwayXY = get_xy_from_geometry(subway.to_crs(epsg=3857))\n",
    "\n",
    "# STEP 2: Initialize the algorithm\n",
    "nbrs = NearestNeighbors(n_neighbors=1)\n",
    "\n",
    "# STEP 3: Fit the algorithm on the \"neighbors\" dataset\n",
    "nbrs.fit(subwayXY)\n",
    "\n",
    "# STEP 4: Get distances for sale to neighbors\n",
    "subwayDists, subwayIndices = nbrs.kneighbors(salesXY)\n",
    "\n",
    "# STEP 5: add back to the original dataset\n",
    "sales['logDistSubway'] = np.log10(subwayDists[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's plot a hex map again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10), facecolor=plt.get_cmap('viridis')(0))\n",
    "\n",
    "# Plot the log of the subway distance\n",
    "x = salesXY[:,0]\n",
    "y = salesXY[:,1]\n",
    "ax.hexbin(x, y, C=np.log10(subwayDists.mean(axis=1)), gridsize=60)\n",
    "\n",
    "# Plot the city limits\n",
    "city_limits.plot(ax=ax, facecolor='none', edgecolor='white', linewidth=4)\n",
    "\n",
    "ax.set_axis_off()\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Looks like it worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Now, let's re-run our model...did it help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Numerical columns\n",
    "num_cols = [\n",
    "    \"total_livable_area\",\n",
    "    \"total_area\",\n",
    "    \"garage_spaces\",\n",
    "    \"fireplaces\",\n",
    "    \"number_of_bathrooms\",\n",
    "    \"number_of_bedrooms\",\n",
    "    \"number_stories\",\n",
    "    \"logDistGraffiti\",\n",
    "    \"logDistSubway\"\n",
    "]\n",
    "\n",
    "# Categorical columns\n",
    "cat_cols = [\"exterior_condition\", \"zip_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the column transformer with two transformers\n",
    "# Scale the numerical columns and one-hot \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the pipeline\n",
    "# NOTE: only use 20 estimators here so it will run in a reasonable time\n",
    "regr = make_pipeline(\n",
    "    preprocessor, RandomForestRegressor(n_estimators=20, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data 70/30\n",
    "train_set, test_set = train_test_split(sales, test_size=0.3, random_state=42)\n",
    "\n",
    "# the target labels\n",
    "y_train = np.log(train_set[\"sale_price\"])\n",
    "y_test = np.log(test_set[\"sale_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the training set\n",
    "regr.fit(train_set, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# What's the test score?\n",
    "regr.score(test_set, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Small improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How about the top 30 feature importances now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_feature_importances(regr, num_cols, preprocessor, top=20, **kwargs):\n",
    "    \"\"\"\n",
    "    Utility function to plot the feature importances from the input\n",
    "    random forest regressor\n",
    "    \"\"\"\n",
    "    # The one-hot step\n",
    "    ohe = preprocessor.named_transformers_[\"cat\"]\n",
    "\n",
    "    # One column for each category type!\n",
    "    ohe_cols = ohe.get_feature_names()\n",
    "\n",
    "    # Full list of columns is numerical + one-hot\n",
    "    features = num_cols + list(ohe_cols)\n",
    "\n",
    "    # The regressor\n",
    "    regressor = regr[\"randomforestregressor\"]\n",
    "\n",
    "    # Create the dataframe with importances\n",
    "    importance = pd.DataFrame(\n",
    "        {\"Feature\": features, \"Importance\": regressor.feature_importances_}\n",
    "    )\n",
    "\n",
    "    # Sort importance in descending order and get the top\n",
    "    importance = importance.sort_values(\"Importance\", ascending=False).iloc[:top]\n",
    "\n",
    "    # Plot\n",
    "    return importance.hvplot.barh(x=\"Feature\", y=\"Importance\", flip_yaxis=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_feature_importances(regr, num_cols, preprocessor, top=30, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Both new spatial features are in the top 5 in terms of importance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise: How about other spatial features?\n",
    "\n",
    "- I've listed out several other types of potential sources of new distance-based features from OpenDataPhilly\n",
    "- Choose a few and add new features\n",
    "- Re-fit the model and evalute the performance on the test set and feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Universities\n",
    "\n",
    "New feature: Distance to the *nearest* university/college\n",
    "\n",
    "- Source: [OpenDataPhilly](https://www.opendataphilly.org/dataset/philadelphia-universities-and-colleges)\n",
    "- GeoService URL: https://services.arcgis.com/fLeGjb7u4uXqeF9q/ArcGIS/rest/services/Universities_Colleges/FeatureServer/0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parks\n",
    "\n",
    "New feature: Distance to the *nearest* park centroid\n",
    "\n",
    "* Source: [OpenDataPhilly](https://www.opendataphilly.org/dataset/parks-and-recreation-assets)\n",
    "* GeoService URL: https://services.arcgis.com/fLeGjb7u4uXqeF9q/ArcGIS/rest/services/PPR_Assets/FeatureServer/0\n",
    "\n",
    "**Notes** \n",
    "- The park geometries are *polygons*, so you'll need to get the `x` and `y` coordinates of the park *centroids* and calculate the distance to these centroids. \n",
    "- You can use the `geometry.centroid.x` and `geometry.centroid.y` values to access these coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### City Hall\n",
    "\n",
    "New feature: Distance to City Hall.\n",
    "\n",
    "* Source: [OpenDataPhilly](https://www.opendataphilly.org/dataset/city-landmarks)\n",
    "* GeoService URL: https://services.arcgis.com/fLeGjb7u4uXqeF9q/ArcGIS/rest/services/CITY_LANDMARKS/FeatureServer/0\n",
    "\n",
    "**Notes**\n",
    "\n",
    "- To identify City Hall, you'll need to pull data where \"NAME='City Hall'\" and \"FEAT_TYPE='Municipal Building'\"\n",
    "- As with the parks, the geometry will be a *polygon*, so you should calculate the distance to the *centroid* of the City Hall polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### New Construction Permits\n",
    "\n",
    "New feature: Distance to the 5 nearest new construction permits from 2018\n",
    "\n",
    "* Source: [OpenDataPhilly](https://www.opendataphilly.org/dataset/licenses-and-inspections-building-permits)\n",
    "* CARTO table name: \"li_permits\"\n",
    "\n",
    "**Notes**\n",
    "\n",
    "* You can pull new construction permits only by selecting where `permitdescription` equals 'NEW CONSTRUCTION PERMIT'\n",
    "* You can select permits from only 2018 using the `permitissuedate` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aggravated Assaults\n",
    "\n",
    "New feature: Distance to the 5 nearest aggravated assaults in 2018\n",
    "\n",
    "* Source: [OpenDataPhilly](https://www.opendataphilly.org/dataset/crime-incidents)\n",
    "* CARTO table name: \"incidents_part1_part2\"\n",
    "\n",
    "**Notes**\n",
    "\n",
    "* You can pull aggravated assaults only by selecting where `Text_General_Code` equals 'Aggravated Assault No Firearm' or 'Aggravated Assault Firearm'\n",
    "* You can select crimes from only 2018 using the `dispatch_date` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Abandonded Vehicle 311 Calls\n",
    "\n",
    "New feature: Distance to the 5 nearest abandoned vehicle 311 calls in 2018\n",
    "\n",
    "* Source: [OpenDataPhilly](https://www.opendataphilly.org/dataset/311-service-and-information-requests)\n",
    "* CARTO table name: \"public_cases_fc\"\n",
    "\n",
    "**Notes**\n",
    "\n",
    "* You can pull abandonded vehicle calls only by selecting where `service_name` equals 'Abandoned Vehicle'\n",
    "* You can select crimes from only 2018 using the `requested_datetime` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 2: Predicting bikeshare demand in Philadelphia\n",
    "\n",
    "**The technical problem**: predict bikeshare trip counts for the Indego bikeshare in Philadelphia\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The policy question: how to best expand a bikeshare program?\n",
    "\n",
    "- Bikeshares typically require substantial capital when first launching, about \\\\$4,000 to \\\\$5,000 per bike\n",
    "- Once launched, revenue from riders typically covers about 80 percent of operating costs\n",
    "- Ridership peaks in busy downtown hubs, but how to best expand outwards, often to low-density and low-income communities?\n",
    "- Important cost/benefit questions of how/where to expand to maximize ridership and access and minimize the need for outside subsidies\n",
    "\n",
    "For more info, see [this blog post](https://www.pewtrusts.org/en/research-and-analysis/blogs/stateline/2016/03/24/despite-popularity-bike-share-programs-often-need-subsidies) from Pew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using predictive modeling as a policy tool\n",
    "\n",
    "- Construct a predictive model for trip counts by stations in a bikeshare\n",
    "- Use this model to estimate and map out the ridership for potential stations in new areas\n",
    "- Use the cost per ride to estimate the additional revenue added\n",
    "- Compare this additional revenue to the cost of adding new stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What are the key assumptions here?\n",
    "\n",
    "**Most important:** adding new stations in new areas will not affect the demand for existing stations.\n",
    "\n",
    "This allows the results from the predictive model for demand, built on existing stations, to translate to new stations. \n",
    "\n",
    "The key assumption is that the bikeshare is not yet at full capacity, and riders in new areas will not decrease the demand in other areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Is this a good assumption?\n",
    "\n",
    "- Given that the bikeshare is looking to expand, it's a safe bet that they believe the program is not yet at full capacity\n",
    "- This is verifiable with existing data — examine trip counts in neighboring stations when a new station opens up. \n",
    "\n",
    "**Typically, this is a pretty safe assumption.** But I encourage you to use historical data to verify it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Two important columns:**\n",
    "\n",
    "- `totalDocks`: the total number of docks at each station\n",
    "- `kioskId`: the unique identifier for each station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Getting trip data for the Indego bike share\n",
    "\n",
    "- Available by quarter from: https://www.rideindego.com/about/data/\n",
    "- I've pulled trip data for 2018 and 2019 (through Q3) and combined into a single CSV file (available in the data folder)\n",
    "\n",
    "The data page also includes the live status of all of the stations in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get the live station status\n",
    "stations = gpd.read_file(\"http://www.rideindego.com/stations/json/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's plot the stations, colored by the number of docks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# stations\n",
    "stations_3857 = stations.to_crs(epsg=3857)\n",
    "stations_3857.plot(ax=ax, column='totalDocks', legend=True)\n",
    "\n",
    "# plot the basemap underneath\n",
    "ctx.add_basemap(ax=ax, crs=stations_3857.crs, url=ctx.providers.CartoDB.DarkMatter)\n",
    "\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load all trips from 2018 and 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhand/anaconda3/envs/py37/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "all_trips = pd.read_csv(\"./data/indego-trips-2018-2019.csv.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "all_trips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dependent variable: total trips by starting station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "start_trips = all_trips.groupby(\"start_station\").size().reset_index(name=\"total_start_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Now merge in the geometry for each station\n",
    "bike_data = (\n",
    "    stations[[\"geometry\", \"kioskId\"]]\n",
    "    .merge(start_trips, left_on=\"kioskId\", right_on=\"start_station\")\n",
    "    .to_crs(epsg=3857)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's plot it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# stations\n",
    "bike_data.plot(ax=ax, column='total_start_trips', legend=True)\n",
    "\n",
    "# plot the basemap underneath\n",
    "ctx.add_basemap(ax=ax, crs=bike_data.crs, url=ctx.providers.CartoDB.DarkMatter)\n",
    "\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Trips are clearly concentrated in Center City..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What features to use?\n",
    "\n",
    "There are lots of possible options. Generally speaking, the possible features fall into a few different categories:\n",
    "\n",
    "- **Internal**\n",
    "    - e.g., the number of docks per station\n",
    "- **Demographic (Census)**    \n",
    "    - e.g., population, income, percent commuting by car, percent with bachelor's degree or higher, etc\n",
    "- **Amenities/Disamenities**\n",
    "    - e.g., distance to nearest crimes, restaurants, parks, within Center City Business District, etc\n",
    "- **Transportation network**\n",
    "    - e.g., distance to nearest bus stop, interesection nodes, nearest subway stop\n",
    "- **Neighboring stations**\n",
    "    - e.g., average trips of nearest stations, distance to nearest stations\n",
    "    \n",
    "**Let's add a few from each category...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Internal characteristics\n",
    "\n",
    "Let's use the number of docks per stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bike_data = bike_data.merge(stations[[\"kioskId\", \"totalDocks\"]], on=\"kioskId\")\n",
    "bike_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Census demographic data\n",
    "\n",
    "We'll try out percent commuting by car first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from census import Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Note that using an API key of \"None\" should work for most use cases\n",
    "c = Census(key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Variable names chosen from: https://api.census.gov/data/2017/acs/acs5/variables.html\n",
    "# This is the total number of commuters and those commuting by car\n",
    "variables = (\"NAME\", \"B08134_001E\", \"B08134_011E\")\n",
    "census_data = pd.DataFrame(c.acs5.state_county_tract(variables, \"42\", \"101\", \"*\"))\n",
    "\n",
    "# The percent commuting by car\n",
    "census_data[\"percent_car\"] = census_data[\"B08134_011E\"] / census_data[\"B08134_001E\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "census_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Merge with census tract geometries for Philadelphia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pa_tracts = gpd.read_file(us.states.PA.shapefile_urls('tract'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "census_data = pa_tracts.merge(\n",
    "    census_data,\n",
    "    left_on=[\"STATEFP10\", \"COUNTYFP10\", \"TRACTCE10\"],\n",
    "    right_on=[\"state\", \"county\", \"tract\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, let's merge the census data into our dataframe of features by spatially joining the stations and the census tracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bike_data = gpd.sjoin(\n",
    "    bike_data,\n",
    "    census_data.to_crs(bike_data.crs)[[\"geometry\", \"percent_car\"]],\n",
    "    op=\"within\",\n",
    ").drop(labels=['index_right'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bike_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\"Impute\" missing values with the median value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "missing = bike_data['percent_car'].isnull()\n",
    "bike_data.loc[missing, 'percent_car'] = bike_data['percent_car'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Amenities/disamenities\n",
    "\n",
    "Let's add two new features:\n",
    "\n",
    "1. Distances to the nearest 10 restaurants from Open Street Map\n",
    "1. Whether the station is within the Center City Business District"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Restaurants\n",
    "\n",
    "Search https://wiki.openstreetmap.org/wiki/Map_Features for OSM identifier of restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "restaurants = osm2gpd.get(lng_min, lat_min, lng_max, lat_max, where=\"amenity=restaurant\").to_crs(epsg=3857)\n",
    "restaurants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Get x/y values for the stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stationsXY = get_xy_from_geometry(bike_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# STEP 1: x/y coordinates of restaurants (in EPGS=3857)\n",
    "restsXY = get_xy_from_geometry(restaurants.to_crs(epsg=3857))\n",
    "\n",
    "# STEP 2: Initialize the algorithm\n",
    "nbrs = NearestNeighbors(n_neighbors=5)\n",
    "\n",
    "# STEP 3: Fit the algorithm on the \"neighbors\" dataset\n",
    "nbrs.fit(restsXY)\n",
    "\n",
    "# STEP 4: Get distances for stations to neighbors\n",
    "restsDists, restsIndices = nbrs.kneighbors(stationsXY)\n",
    "\n",
    "# STEP 5: add back to the original dataset\n",
    "bike_data['logDistRests'] = np.log10(restsDists.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bike_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# stations\n",
    "bike_data.plot(ax=ax, column='logDistRests', legend=True)\n",
    "\n",
    "# plot the basemap underneath\n",
    "ctx.add_basemap(ax=ax, crs=bike_data.crs, url=ctx.providers.CartoDB.DarkMatter)\n",
    "\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Center City Business District\n",
    "\n",
    "Available from [OpenDataPhilly](https://www.opendataphilly.org/dataset/center-city-business-improvement-district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "url = \"http://data.phl.opendata.arcgis.com/datasets/95366b115d93443eae4cc6f498cb3ca3_0.geojson\"\n",
    "cc_bid = gpd.read_file(url).to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cc_bid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cc_bid_geo = cc_bid.iloc[0].geometry\n",
    "\n",
    "cc_bid_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bike_data['within_cc_bid'] = bike_data.geometry.within(cc_bid_geo).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bike_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transportation Network\n",
    "\n",
    "- Let's add a feature that calculates the distance to the nearest intersections\n",
    "- We can use the osmnx package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import osmnx as ox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax = bike_data.to_crs(epsg=4326).total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ox.graph_from_bbox?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "G = ox.graph_from_bbox(ymax, ymin, xmax, xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "interesections = ox.graph_to_gdfs(G, nodes=True, edges=False).to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "interesections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# STEP 1: x/y coordinates of restaurants (in EPGS=3857)\n",
    "intersectionsXY = get_xy_from_geometry(interesections.to_crs(epsg=3857))\n",
    "\n",
    "# STEP 2: Initialize the algorithm\n",
    "nbrs = NearestNeighbors(n_neighbors=10)\n",
    "\n",
    "# STEP 3: Fit the algorithm on the \"neighbors\" dataset\n",
    "nbrs.fit(intersectionsXY)\n",
    "\n",
    "# STEP 4: Get distances for stations to neighbors\n",
    "interDists, interIndices = nbrs.kneighbors(stationsXY)\n",
    "\n",
    "# STEP 5: add back to the original dataset\n",
    "bike_data['logIntersectionDists'] = np.log10(interDists.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# stations\n",
    "bike_data.plot(ax=ax, column='logIntersectionDists', legend=True)\n",
    "\n",
    "# plot the basemap underneath\n",
    "ctx.add_basemap(ax=ax, crs=bike_data.crs, url=ctx.providers.CartoDB.DarkMatter)\n",
    "\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Neighboring Stations\n",
    "\n",
    "- We need to include features that encodes the fact that demand for a specific station is likely related to the demand in neighboring stations\n",
    "- This idea is known as **spatial lag**\n",
    "\n",
    "We will add two new features:\n",
    "\n",
    "1. The average distance to the nearest 5 stations\n",
    "1. The average trip total for the nearest 5 stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, find the nearest 5 stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "k = 6\n",
    "nbrs = NearestNeighbors(n_neighbors=k)\n",
    "nbrs.fit(stationsXY)\n",
    "\n",
    "stationDists, stationIndices = nbrs.kneighbors(stationsXY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Notes**\n",
    "\n",
    "- We are matching the stations to themselves to find the nearest neighbors\n",
    "- The closest match will always be the same station (distance of 0)\n",
    "- So we fit for $k+1$ neighbors and will remove the closest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bike_data['logStationDists'] = np.log10(stationDists[:,1:].mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# stations\n",
    "bike_data.plot(ax=ax, column='logStationDists', legend=True)\n",
    "\n",
    "# plot the basemap underneath\n",
    "ctx.add_basemap(ax=ax, crs=bike_data.crs, url=ctx.providers.CartoDB.DarkMatter)\n",
    "\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# the total trips for the stations\n",
    "total_start_trips = bike_data['total_start_trips'].values\n",
    "\n",
    "# get the trips for the 5 nearest neighbors (ignoring first match)\n",
    "neighboring_trips = total_start_trips[stationIndices[:,1:]]\n",
    "\n",
    "# add to features\n",
    "bike_data['laggedTrips'] = neighboring_trips.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's fit a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bike_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perform our test/train split\n",
    "\n",
    "We'll use a 60%/40% split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "bike_features = bike_data.drop(labels=[\"geometry\", \"kioskId\", \"start_station\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data 60/40\n",
    "train_set, test_set = train_test_split(\n",
    "    bike_features,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# the target labels\n",
    "y_train = np.log(train_set[\"total_start_trips\"])\n",
    "y_test = np.log(test_set[\"total_start_trips\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_set = train_set.drop(labels=['total_start_trips'], axis=1)\n",
    "test_set = test_set.drop(labels=['total_start_trips'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random forest results\n",
    "\n",
    "Let's run a simple grid search to try to optimize our hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "regr = make_pipeline(\n",
    "    StandardScaler(), RandomForestRegressor(random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"randomforestregressor\"\n",
    "param_grid = {\n",
    "    f\"{model_name}__n_estimators\": [5, 10, 15, 20, 30, 50, 100, 200],\n",
    "    f\"{model_name}__max_depth\": [2, 5, 7, 9, 13, 21, 33, 51, 100],\n",
    "}\n",
    "\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create the grid and use 3-fold CV\n",
    "grid = GridSearchCV(regr, param_grid, cv=3)\n",
    "\n",
    "# Run the search\n",
    "grid.fit(train_set.values, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the best random forest model\n",
    "best_random = grid.best_estimator_\n",
    "best_random.score(test_set, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "linear = make_pipeline(StandardScaler(), LinearRegression())\n",
    "\n",
    "# Fit on train set\n",
    "linear.fit(train_set, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "linear.score(test_set, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The regressor\n",
    "regressor = grid.best_estimator_[\"randomforestregressor\"]\n",
    "\n",
    "# Create the dataframe with importances\n",
    "importance = pd.DataFrame(\n",
    "    {\"Feature\": train_set.columns, \"Importance\": regressor.feature_importances_}\n",
    ")\n",
    "\n",
    "# Sort importance in descending order and get the top\n",
    "importance = importance.sort_values(\"Importance\", ascending=False).iloc[:50]\n",
    "\n",
    "# Plot\n",
    "importance.hvplot.barh(x=\"Feature\", y=\"Importance\", flip_yaxis=True, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's analyze the spatial structure of the predictions visually\n",
    "\n",
    "We'll plot the predicted and actual trip values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the test data from the original dataset\n",
    "# This will include the geometry data\n",
    "X = bike_data.loc[test_set.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the predicted test values from log\n",
    "X['prediction'] = np.exp(grid.best_estimator_.predict(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot two columns\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10,10))\n",
    "\n",
    "# Predicted values\n",
    "X.plot(ax=axs[0], column='prediction')\n",
    "ctx.add_basemap(ax=axs[0], crs=X.crs, url=ctx.providers.CartoDB.DarkMatter)\n",
    "axs[0].set_title(\"Predicted Trip Counts\")\n",
    "\n",
    "# Actual values\n",
    "X.plot(ax=axs[1], column='total_start_trips')\n",
    "ctx.add_basemap(ax=axs[1], crs=X.crs, url=ctx.providers.CartoDB.DarkMatter)\n",
    "axs[1].set_title(\"Actual Trip Counts\")\n",
    "\n",
    "\n",
    "axs[0].set_axis_off()\n",
    "axs[1].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise: can we improve the model?\n",
    "\n",
    "Yes! This is a classic example of underfitting. With only ten features, we should be able to improve with new features?\n",
    "\n",
    "**Options**\n",
    "- Additional census demographic data: \n",
    "    - e.g., population, income, percent with bachelor's degree or higher\n",
    "    - See https://api.census.gov/data/2017/acs/acs5/variables.html for column names!\n",
    "- Amenities / disamenities\n",
    "    - Lots of options from OpenDataPhilly and OpenStreetMap\n",
    "- Transportation network\n",
    "    - Distance to the nearest bus station is a good place to start (see https://wiki.openstreetmap.org/wiki/Map_Features for the amenity tag)\n",
    "- Changing $k$ values for distance-based features\n",
    "    - Experiment with different values of $k$ to see if they improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other options\n",
    "\n",
    "When trying to improve the accuracy of the model, another option is incorporating additional data. In this case, we can look to other cities and include trip data for these cities. Some good places to start:\n",
    "\n",
    "- [Boston](https://www.bluebikes.com/)\n",
    "- [Chicago](https://www.divvybikes.com/)\n",
    "- [Washington D.C](https://www.capitalbikeshare.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
